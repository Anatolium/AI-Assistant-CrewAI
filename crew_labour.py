import os
from dotenv import load_dotenv
import requests
from common import create_agents, create_tasks, build_crew
from datetime import datetime

load_dotenv()

openai_api_key = os.getenv("OPENAI_API_KEY")
openai_api_base = os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1")

if not openai_api_key:
    raise ValueError("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")

os.environ["OPENAI_API_KEY"] = openai_api_key
os.environ["OPENAI_API_BASE"] = openai_api_base

print("üîç –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ LLM...")


def check_ollama_available():
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=3)
        return response.status_code == 200
    except Exception:
        return False


use_ollama = check_ollama_available()

if use_ollama:
    print("‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω Ollama ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å")
    from crewai.llms.base_llm import BaseLLM


    class OllamaCustomLLM(BaseLLM):
        def __init__(self, model="deepseek-r1:8b", base_url="http://localhost:11434"):
            super().__init__(model=model)
            self.base_url = base_url

        def call(self, messages, **kwargs):
            prompt = messages[-1].get("content", "") if isinstance(messages, list) else str(messages)
            try:
                response = requests.post(
                    f"{self.base_url}/api/generate",
                    json={
                        "model": self.model,
                        "prompt": prompt,
                        "stream": False,
                    },
                    timeout=600
                )
                response.raise_for_status()
                return response.json().get("response", "")
            except Exception as e:
                raise RuntimeError(f"–û—à–∏–±–∫–∞ Ollama: {e}")


    llm = OllamaCustomLLM()
else:
    print("‚ÑπÔ∏è Ollama –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è OpenAI API")
    llm = None  # CrewAI –≤–æ–∑—å–º–µ—Ç OpenAI –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è

# –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–æ–≤ —Å –Ω—É–∂–Ω—ã–º LLM
researcher, analyst = create_agents(llm)
research_task, report_task = create_tasks(researcher, analyst)
crew = build_crew(researcher, analyst, research_task, report_task)

print(f"üöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –≤–æ—Å—Ç—Ä–µ–±–æ–≤–∞–Ω–Ω—ã—Ö –ò–¢-–Ω–∞–≤—ã–∫–æ–≤ —á–µ—Ä–µ–∑ {'Ollama' if use_ollama else 'OpenAI'}...")

try:
    result = crew.kickoff()

    print("==================================================")
    print("–†–ï–ó–£–õ–¨–¢–ê–¢ –ê–ù–ê–õ–ò–ó–ê:")
    print("==================================================")
    print(result)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    RESULTS_DIR = "results"
    os.makedirs(RESULTS_DIR, exist_ok=True)

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ —Å —Ç–µ–∫—É—â–µ–π –¥–∞—Ç–æ–π –∏ –≤—Ä–µ–º–µ–Ω–µ–º
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_file = os.path.join(RESULTS_DIR, f"result_{timestamp}.md")

    try:
        with open(result_file, "w", encoding="utf-8") as f:
            f.write(str(result))
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ —Ñ–∞–π–ª: {result_file}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e}")

except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏: {e}")
